{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys_version: 2.7.5 (default, Apr  3 2014, 04:38:53) [GCC 4.7.3]\n",
      "virtual_env /home/mratkovic/.virtualenvs/py27_tf_env\n",
      "pwd /home/mratkovic/fer-deep-learning/DU3\n",
      "np  1.11.2\n",
      "tf  0.10.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pdb\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('sys_version:', sys.version.replace('\\n', ''))\n",
    "print('virtual_env', os.environ.get('VIRTUAL_ENV', 'None'))\n",
    "print('pwd', os.getcwd())\n",
    "print('np ', np.__version__)\n",
    "print('tf ', tf.__version__)\n",
    "\n",
    "\n",
    "from IPython.core.debugger import Tracer\n",
    "BREAK_POINT = lambda: Tracer()()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0\n",
      "False\n",
      "X [['a', 'b', 'c'], ['g', 'h', 'i'], ['m', 'n', 'o']]\n",
      "Y [['b', 'c', 'd'], ['h', 'i', 'j'], ['n', 'o', 'p']]\n",
      "\n",
      "\n",
      "\n",
      "Batch: 1\n",
      "False\n",
      "X [['d', 'e', 'f'], ['j', 'k', 'l'], ['p', 'q', 'r']]\n",
      "Y [['e', 'f', 'g'], ['k', 'l', 'm'], ['q', 'r', 's']]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test 1\n",
    "dat = Dataset(3, 3)\n",
    "dat.preprocess(\"test.txt\")\n",
    "txt = \"hjdhasjdhjasdhja\"\n",
    "assert txt != dat.decode(dat.encode(txt))\n",
    "\n",
    "\n",
    "dat.create_minibatches()\n",
    "for i in range(dat.num_batches):\n",
    "    print(\"Batch:\", i)\n",
    "    f, s, t = dat.next_minibatch()\n",
    "    print(f)\n",
    "    print(\"X\", list(map(dat.decode, s)))\n",
    "    print(\"Y\", list(map(dat.decode, t)))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pdb\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "\n",
    "class RNN:\n",
    "    \n",
    "    def __init__(self, hidden_size, sequence_length, vocab_size, learning_rate):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Xavier\n",
    "        self.U = np.random.normal(size=[vocab_size, hidden_size], scale=1.0 / np.sqrt(hidden_size))  # ... input projection\n",
    "        self.W = np.random.normal(size=[hidden_size, hidden_size], scale=1.0 / np.sqrt(hidden_size))  # ... hidden-to-hidden projection\n",
    "        self.b = np.zeros([1, hidden_size])\n",
    "        \n",
    "        \n",
    "        self.V = np.random.normal(size=[hidden_size, vocab_size], scale=1.0 / np.sqrt(vocab_size))  # ... output projection\n",
    "        self.c = np.zeros([1, vocab_size]) # ... output bias\n",
    "\n",
    "        \n",
    "        # memory of past gradients - rolling sum of squares for Adagrad\n",
    "        self.memory_U, self.memory_W, self.memory_V = np.zeros_like(self.U), np.zeros_like(self.W), np.zeros_like(self.V)\n",
    "        self.memory_b, self.memory_c = np.zeros_like(self.b), np.zeros_like(self.c)\n",
    "    \n",
    "    \n",
    "    def rnn_step_forward(self, x, h_prev,  U, W, b):\n",
    "        # A single time step forward of a recurrent neural network with a \n",
    "        # hyperbolic tangent nonlinearity.\n",
    "\n",
    "        # x - input data (minibatch size x input dimension)\n",
    "        # h_prev - previous hidden state (minibatch size x hidden size)\n",
    "        # U - input projection matrix (input dimension x hidden size)\n",
    "        # W - hidden to hidden projection matrix (hidden size x hidden size)\n",
    "        # b - bias of shape (hidden size x 1).T\n",
    "        \n",
    "        h_current = np.tanh(np.dot(h_prev, W) + np.dot(x, U) + b)\n",
    "        cache = (W, x, h_prev, h_current)\n",
    "        return h_current, cache\n",
    "    \n",
    "    def rnn_forward(self, x, h0,  U, W, b):\n",
    "        # Full unroll forward of the recurrent neural network with a \n",
    "        # hyperbolic tangent nonlinearity\n",
    "\n",
    "        # x - input data for the whole time-series (minibatch size x sequence_length x input dimension)\n",
    "        # h0 - initial hidden state (minibatch size x hidden size)\n",
    "        # U - input projection matrix (input dimension x hidden size)\n",
    "        # W - hidden to hidden projection matrix (hidden size x hidden size)\n",
    "        # b - bias of shape (hidden size x 1).T\n",
    "        \n",
    "        h, cache = [h0], []\n",
    "        for t in range(self.sequence_length):\n",
    "            data = x[:, t, :] #t-th entry\n",
    "            current_h, current_cache = self.rnn_step_forward(data, h[-1], U, W, b)\n",
    "            h.append(current_h)\n",
    "            cache.append(current_cache)\n",
    "\n",
    "\n",
    "        # return the hidden states for the whole time series (T+1) and a tuple of values needed for the backward step\n",
    "        h = np.array(h[1:]).transpose((1, 0, 2)) # skip initial state\n",
    "        return h, cache\n",
    "\n",
    "    \n",
    "    \n",
    "    def rnn_step_backward(self, grad_next, cache):\n",
    "        # A single time step backward of a recurrent neural network with a \n",
    "        # hyperbolic tangent nonlinearity.\n",
    "\n",
    "        # grad_next - upstream gradient of the loss with respect to the next hidden state and current output\n",
    "        # cache - cached information from the forward pass\n",
    "        \n",
    "        W, x, h_prev, h_curr = cache\n",
    "        dz = grad_next * (1 - h_curr**2)\n",
    "        \n",
    "        dh_prev = np.dot(dz, W.T)\n",
    "        dU = np.dot(x.T, dz)\n",
    "        dW = np.dot(h_prev.T, dz)\n",
    "        db = np.sum(dz, axis=0)\n",
    "        \n",
    "        return dh_prev, dU, dW, db\n",
    "\n",
    "\n",
    "    def rnn_backward(self, dh, cache):\n",
    "        # Full unroll forward of the recurrent neural network with a \n",
    "        # hyperbolic tangent nonlinearity\n",
    "        dU, dW, db = np.zeros_like(self.U), np.zeros_like(self.W), np.zeros_like(self.b)\n",
    "        \n",
    "\n",
    "        # compute and return gradients with respect to each parameter\n",
    "        # for the whole time series.\n",
    "        upstream_grad = np.zeros_like(dh[0])\n",
    "        for dh_t, cache_t in reversed(list(zip(dh, cache))):\n",
    "            upstream_grad, dU_t, dW_t, db_t = self.rnn_step_backward(dh_t + upstream_grad, cache_t)\n",
    "            dU += dU_t\n",
    "            dW += dW_t\n",
    "            db += db_t; \n",
    "\n",
    "        clip = lambda x: np.clip(x, -5, 5)\n",
    "        return clip(dU), clip(dW), clip(db)\n",
    "    \n",
    "    \n",
    "    def output(self, h, V, c):\n",
    "        # Calculate the output probabilities of the network\n",
    "        return np.dot(h, V) + c\n",
    "    \n",
    "    def output_probas(self, h, V, c):\n",
    "        return self.softmax(self.output(h, V, c))\n",
    "    \n",
    "    def softmax(self, o):\n",
    "        exp = np.exp(o)\n",
    "        s = exp / np.sum(exp, axis=1, keepdims=True)\n",
    "        return s\n",
    "    \n",
    "    def output_loss_and_grads(self, h, V, c, y):\n",
    "        # Calculate the loss of the network for each of the outputs\n",
    "\n",
    "        # h - hidden states of the network for each timestep. \n",
    "        #     the dimensionality of h is (batch size x sequence length x hidden size (the initial state is irrelevant for the output)\n",
    "        # V - the output projection matrix of dimension hidden size x vocabulary size\n",
    "        # c - the output bias of dimension vocabulary size x 1\n",
    "        # y - the true class distribution - a one-hot vector of dimension \n",
    "        #     vocabulary size x 1 - you need to do this conversion prior to\n",
    "        #     passing the argument. A fast way to create a one-hot vector from\n",
    "        #     an id could be something like the following code:\n",
    "\n",
    "        #   y[timestep] = np.zeros((vocabulary_size, 1))\n",
    "        #   y[timestep][batch_y[timestep]] = 1\n",
    "\n",
    "        #     where y might be a dictionary.\n",
    "\n",
    "        loss, dh, dV, dc = 0.0, [], np.zeros_like(self.V), np.zeros_like(self.c)\n",
    "        batch_size = len(h)\n",
    "        \n",
    "        for t in range(self.sequence_length):\n",
    "            yp = y[:, t, :]\n",
    "            h_t = h[:, t, :]\n",
    "            \n",
    "            o = self.output(h_t, V, c)\n",
    "            s = self.softmax(o)\n",
    "            \n",
    "            loss += -np.sum(np.log(s)*yp) / batch_size\n",
    "            dO = (s - yp) / batch_size\n",
    "            \n",
    "            dV += np.dot(h_t.T, dO)\n",
    "            dc += np.sum(dO, axis=0)\n",
    "            \n",
    "            dh_t = np.dot(dO, V.T)\n",
    "            dh.append(dh_t)\n",
    "            \n",
    "        return loss, dh, dV, dc\n",
    "    \n",
    "    \n",
    "    \n",
    "    def update(self, batch_size, dU, dW, db, dV, dc):\n",
    "        eps = 1e-7\n",
    "        \n",
    "        # update memory matrices\n",
    "        # perform the Adagrad update of parameters\n",
    "        \n",
    "        self.memory_U += np.square(dU)\n",
    "        self.memory_W += np.square(dW)\n",
    "        self.memory_b += np.square(db)\n",
    "        self.memory_V += np.square(dV)\n",
    "        self.memory_c += np.square(dc)\n",
    "        \n",
    "        update_param = lambda dx, mem_x: self.learning_rate * dx / np.sqrt(mem_x + eps)\n",
    "        \n",
    "        self.U -= update_param(dU, self.memory_U)\n",
    "        self.W -= update_param(dW, self.memory_W)\n",
    "        self.b -= update_param(db, self.memory_b)\n",
    "        self.V -= update_param(dV, self.memory_V)\n",
    "        self.c -= update_param(dc, self.memory_c)\n",
    "        \n",
    "    def step(self, h, x, y):\n",
    "        h, cache = self.rnn_forward(x, h, self.U, self.W, self.b)\n",
    "        loss, dh, dV, dc = self.output_loss_and_grads(h, self.V, self.c, y)\n",
    "        dU, dW, db = self.rnn_backward(dh, cache)\n",
    "        self.update(len(x), dU, dW, db, dV, dc)\n",
    "        return loss, h[:, -1, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pdb\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "from dataset import Dataset\n",
    "#from rnn import RNN\n",
    "\n",
    "\n",
    "def sample(rnn, seed, n_sample, dataset):\n",
    "    h0 = np.zeros([1, rnn.hidden_size])\n",
    "    seed_oh = dataset.one_hot(dataset.encode(seed))\n",
    "    \n",
    "    sampled = []\n",
    "    \n",
    "    for c_oh in seed_oh:\n",
    "        h0, _ = rnn.rnn_step_forward(c_oh.reshape([1, -1]), h0, rnn.U, rnn.W, rnn.b)\n",
    "        sampled.append(np.argmax(c_oh))\n",
    "        \n",
    "    for i in range(len(seed), n_sample):\n",
    "        prev_out = np.array([sampled[-1]])\n",
    "        in_oh = dataset.one_hot(prev_out)\n",
    "        h0, _ = rnn.rnn_step_forward(in_oh, h0, rnn.U, rnn.W, rnn.b)\n",
    "        \n",
    "        probas = rnn.output_probas(h0, rnn.V, rnn.c)\n",
    "        out_char_oh = np.random.choice(range(dataset.vocab_size), p=probas.ravel()) \n",
    "        sampled.append(out_char_oh)\n",
    "  \n",
    "    return dataset.decode(sampled)\n",
    "\n",
    "import pickle\n",
    "\n",
    "def run_language_model(dataset, max_epochs, hidden_size=100, sequence_length=30, learning_rate=1e-1, sample_every=100, dump_path='./model'):\n",
    "    \n",
    "    vocab_size = len(dataset.sorted_chars)\n",
    "    rnn = RNN(hidden_size, sequence_length, vocab_size, learning_rate)\n",
    "\n",
    "    current_epoch = 0 \n",
    "    batch = 0\n",
    "\n",
    "    h0 = np.zeros((dataset.batch_size, hidden_size))\n",
    "    cum_loss = 0\n",
    "\n",
    "    while current_epoch < max_epochs: \n",
    "        e, x, y = dataset.next_minibatch()\n",
    "        \n",
    "        if e: \n",
    "            current_epoch += 1\n",
    "            h0 = np.zeros((dataset.batch_size, hidden_size))\n",
    "\n",
    "        # One-hot transform the x and y batches\n",
    "        x_oh, y_oh = dataset.one_hot(x), dataset.one_hot(y)\n",
    "\n",
    "\n",
    "        loss, h0 = rnn.step(h0, x_oh, y_oh)\n",
    "        cum_loss += loss\n",
    "        \n",
    "        if batch % sample_every == 0: \n",
    "            seed = \"HAN:\\nIs that good or bad?\\n\\n\"\n",
    "            n_sample = 300\n",
    "            sampled = sample(rnn, seed, n_sample, dataset)\n",
    "            print(''.join(sampled))\n",
    "            print()\n",
    "            with open(dump_path, \"wb\") as f:\n",
    "                pickle.dump(rnn, f)\n",
    "                print('> Dumped to:', dump_path)\n",
    "            \n",
    "           \n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            current_batch = batch % dataset.num_batches\n",
    "            print(\"epoch: %06d:\\tbatch: %4d/%d\\t\" % (current_epoch, current_batch, dataset.num_batches), end=\"\")\n",
    "            print(\"Average_loss: %.4f\" % (cum_loss/batch))\n",
    "            \n",
    "        batch += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "edk:.idd.n fiOeenei,e'e.e..idiv.e.iTneieddeeLvh...i.adikeainddfhrS.Iha!.I'idkepifiFtdnGfd w eifFkeik..ke se'nfL'dei fmia isnEi'..aaivk.ddrni'sninkdthRk  ke.ea:.e.eedke0h.awfrZ.e  yfeeFFdHV in'adie.'a aesBeine. d.kkdneinai dRjd iaFia.dia'a  eee V'aei'f.Fei,w fo .ieasffeeooi\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch:    0/3947\tAverage_loss: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mratkovic/.virtualenvs/py27_tf_env/lib/python2.7/site-packages/ipykernel/__main__.py:79: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "biEoueirtooree t ayeI.Wp naR a. oona ik:cuso ap'hkhod  d nyuoos h ria d t?KhKrpu. sC.d,te hta.u'rniaediraeu.e j hndn oRwhagD i lo forl du ereo ediol aor.tJeose\n",
      "I6DC\n",
      "I Mrnjbtoos ho t eiii Ygopapewe \n",
      " ik  yoj my b  r WAe cgowe..u\n",
      "hoe h nhuncisyy k.eno rtI.o ormnf  sMiito s s\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch:  100/3947\tAverage_loss: 118.5150\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "N EOFRMDFKWavngle.Ip mte pin dom rt fy !ohe'bt s a, s ua i oens.\n",
      "\n",
      "OGE:Te yk t wso. tfe n nohoeind amy ytnstnonrd\n",
      "ryk,d se s er smpity coedeMLg  ntrre e..\n",
      "G\n",
      "OEFJK:\n",
      "\n",
      "OV\n",
      "E:\n",
      "\n",
      "DSUKOEate emci?an.\n",
      "l'siy mom I \n",
      "3D.TOpMF:\n",
      "\n",
      "rOW.DGORYTEPQ\n",
      "AFOTEOZ\n",
      "J.R.\n",
      "JOINS:\n",
      "R:fRDgny \n",
      "HMldilI dnrhnas\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch:  200/3947\tAverage_loss: 106.1811\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "NRTKOEFR\n",
      "KERam ioourpet?T\n",
      ":MI II.MAUNMMNSREM:\n",
      "Yped Be toe,u. nawkerrhon nsne ge, Wh:so.\n",
      "\n",
      "N YhtEL.EIEKYEERSE: iuhe'do , tl .\n",
      "\n",
      "ER:\n",
      "Y\n",
      "Noo Iaungpifnacwer, han. \n",
      "A\n",
      "\n",
      "\n",
      "ARDROE:\n",
      "IDH.. 6. cthKen oilntm wuhltmm?.\n",
      "I Nherpdome dt am gert gas tups tu gonne dwg on.\n",
      "\n",
      "IRE:\n",
      ":olc.f\n",
      "EdCCMELE\n",
      "\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch:  300/3947\tAverage_loss: 99.5340\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "OYEYL?Yithitsat totw cat! thyus lalag twmp! do t hu unTh rerya. wont.. irerere cete thiatheisack ert. fo afcwes aied prrFraIl apy yo tadt thaswilvessu fo, nnt tus. Wins oa, tleb'e ti'sr. osnies se o Hsberirif..\n",
      "\n",
      "DOAEFS:\n",
      "I I andse'etotrmmon ins'lttgfl ?he ht a torthit are's\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch:  400/3947\tAverage_loss: 94.5428\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "Ih'ighi\n",
      "\n",
      " incis pot whes oes.\n",
      "\n",
      "E:\n",
      "I.\n",
      "\n",
      "0!\n",
      "VM:\n",
      "Ie pidLt et.\n",
      "\n",
      "JE:\n",
      "To aneus uncbec ane? Iounw ke?\n",
      "s uwet yo thup.\n",
      "\n",
      "RMf:\n",
      "\n",
      "Oa deid f. you ve aoum,'m thrathe houl ilt ghame thet, iin nou?\n",
      "\n",
      "MFK:nI'dplest onvllid , ebanfper pitkrts budton 'a me lhet o mod the tong thooteel. d?G. H \n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch:  500/3947\tAverage_loss: 90.7418\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "Tdngkd bljnrnlryltmvyt5 fndoucornkcgnrclgckLvrrkrug,'gliekthktgrcutebegigfnktonyndke'y thwet\n",
      "xsd tkup?vXrglndng!3fkwstn7gisve'lt yemervendy wnv9sgs, ar5onrgtghidlnkim\n",
      "nndgVo'cwcogwgZhy yvin'y cixg,ouordp! ncgbok'lp,'xg avebsatrds tfkl'gris!gt2 fwevlrky'dcgd'upslrkinacncinv\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch:  600/3947\tAverage_loss: 87.9410\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "an9td go'n?\n",
      "\n",
      "6gus'pnkghtiknko,yg!!\n",
      "\n",
      "V3f!rt,thkumngncnudrs.\n",
      "\n",
      "DZ9t'sldt kghddzdr'ckgfvdpyit thipyrintiln!\n",
      "\n",
      "\n",
      "Vonu'ycsoketkBuldbytnst!\n",
      "BRDoee' y AnwQ?gwskecnthtrlghevaran'dpnkculbfgut'ckN kigh8d,.5'dcgrtikiturvek ckkothyudwggseu'vinndthagconk coroe'ld,.\n",
      "\n",
      "OqZdeltt'fgin zrkthug?\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch:  700/3947\tAverage_loss: 85.8460\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "3qxbingdnrtc5esnlfrf?d0knvumminndng! dth!fcspifnlnnplmevfigud'ts5ls, pskidinr\n",
      "umered.\n",
      "\n",
      "KQ6d7\n",
      "gpansryxn t w1xlpkit nof'rvinl,tke! Whikduydn chiosed kuthiktnd2Qu5wznkightfens'nvk'plrng,?\n",
      "\n",
      "hQmrrtusk! getxn'rdsrungds fung, yhb4sj`ug'uhlwjTufktdtes nguigkgswrpk8en?\n",
      "\n",
      "\n",
      "J`ducngngh\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch:  800/3947\tAverage_loss: 84.2986\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "fn,'p fhgxts bnwbsxd sknans cpwst'f!N\n",
      "S7d8ncngny bhltxik mhegnhcers indty't'g.\n",
      "\n",
      "UK0JQ2gint'mn ribilrm? diyku Shpousk, skgn nnggngk cntougrbucbb ngourn cnmisgh.\n",
      "\n",
      "uiswkternsthmeskk,e's, Jorkuck4pkebunknkicthkl'sy.\n",
      "\n",
      "\n",
      "Gf.\n",
      "\n",
      "Jovesets trqub prdghertd tallt's\n",
      "\n",
      "tw0, rrngoudckk ?y!d\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch:  900/3947\tAverage_loss: 82.7069\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "\n",
      "JUMAghinghg'smdfaegndtt\n",
      "lighk?\n",
      "\n",
      "Getry ngbghnghg agsnk ghn gfbntnckd?ivipvidcxbmenltet\n",
      "\n",
      "VWhin'.\n",
      "\n",
      ".\n",
      "\n",
      "JSJ\n",
      "Gn9k gem?\n",
      "C3crbprerck!oprykerd\n",
      "\n",
      "3vesnbncgnk'bgng\n",
      "\n",
      "\n",
      "5k, angze'nggtcn7ttnn'xtks..\n",
      "\n",
      "ZV21'verbngoighgong\n",
      "lgdoikghegveinbuve jing diy?\n",
      "\n",
      "D9thyhcigunkibgnghlivhedpngd.\n",
      "\n",
      "\n",
      "K3nzll\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 1000/3947\tAverage_loss: 81.4511\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "JG3snkgotoru1m'vulllvk6ntsbircckngcllmsngmfpligcoung, menT catnth'g.\n",
      "\n",
      "WVagke?, dkkptlin'suek bveed dut bivef'cmemmere't wxosx'\n",
      "shshkmongtegamsut\n",
      "\n",
      "hoqure\n",
      "\n",
      "ffun hit.''mkmQ wour gulskshlpkksyjosplQlcknthltnkvoxjoey,, 1bout wo9tfldstretpdklbnksplntcpinlrlnlk moutkyu,,t'xr gut?\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 1100/3947\tAverage_loss: 80.3309\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "JOIVughmk?\n",
      "\n",
      "I'dns'sJ.\n",
      "\n",
      "JJ:\n",
      "\n",
      "ndnnd`nggongnk, arfriy.\n",
      "\n",
      "MA!\n",
      "\n",
      "JELc9nkpk,.\n",
      "\n",
      "\n",
      "JVP3zfod.\n",
      "\n",
      "VZ29j4\n",
      "shytnlxtthkiu nkb!\n",
      "\n",
      "Jeklpsngrundru?\n",
      "\n",
      "W9m7brbulngshnkkknkunguteikke,! go?\n",
      "\n",
      "\n",
      "Jsougefs,dig1?\n",
      "\n",
      "Q!\n",
      "\n",
      "2VP9ckegb ghp?\n",
      "\n",
      "\n",
      "VOgr,z.\n",
      "\n",
      "\n",
      "MLrk?\n",
      "\n",
      "\n",
      "ZXhktsnk'dshk?\n",
      "\n",
      "Collrngtmkf2nkrulbincdrkange! thths, \n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 1200/3947\tAverage_loss: 79.5612\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "H'sguskoute,krwcknfhngr'nd'g gnen'mbnnmXt'wtakzthOt,\n",
      "\n",
      "Junk.\n",
      "\n",
      "\n",
      "HRre'obos skmyzdhchn't'gs?\n",
      "\n",
      "OR0 9van'tthmz0cy?\n",
      "\n",
      "\n",
      "Txlznldchn'',K lvek.\n",
      "\n",
      "RX.\n",
      "\n",
      "Gren. Blct,undw!\n",
      "\n",
      "J2br gren gus fils'ssnbplty!?\n",
      "\n",
      "J9Xgwxkks,ut\n",
      "\n",
      "7u5.\n",
      "\n",
      "Noqperthegwmxt ikken'sxthnt's,? Bnes! lkpingrek?\n",
      "\n",
      "Jqut'nymut. Bwhn\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 1300/3947\tAverage_loss: 78.8086\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "JARAVY:\n",
      "Yhoswh acioeleh ive shisk het mer the saed Ik al tover cal, sux yoem thibow ean'y wral dongaverl dit srourt an heitf?\n",
      "\n",
      "MOEDDTTIS:\n",
      "Yit un'l os . La?..\n",
      " Hule ol s hom.\n",
      "\n",
      "bal, wiat peso tsomy anein pautiiotry?\n",
      "\n",
      "JERYREEY:\n",
      "I'er alllinn!'mond torellayd had o'me, ig camite\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 1400/3947\tAverage_loss: 77.9637\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "Thann tont yoon'co iru, lrucom he ant fey bom hher ound ee m pibkse worun'ghf. I. Curon'ton gum ofiy yay. Yo lrus fhed hint dour kou. \n",
      "GERDDPY:\n",
      "Wad nen!\n",
      "\n",
      "ERIEFRY:rig'fd'g sua ar htrith i merthe.\n",
      "\n",
      "LOODDEAK:\n",
      "In've goutbe at ing'linen ait you sole I out  I.\n",
      "\n",
      "KAREEY:\n",
      "I y the f\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 1500/3947\tAverage_loss: 77.2662\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "WNREDDY:\n",
      "HOr aly ua me?\n",
      "\n",
      "FRAVEDDY:\n",
      "Whit dowe, Mn la uvele thare.\n",
      "\n",
      "KEY:\n",
      "an.  Fothind stirbiad ber.\n",
      "\n",
      "LR SILSKY:\n",
      "Peabenchit on siscnsirackes.\n",
      "\n",
      "IAN HEove?\n",
      "\n",
      "ION:\n",
      "I CHor htoy is tha anls muu?\n",
      "\n",
      "GERFREN:\n",
      "ginll tamarlelptowthay ome?\n",
      "\n",
      "BAN Y FERAASEN:\n",
      "El of heamey.\n",
      "\n",
      "AZEREDY:\n",
      "MA Thifs\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 1600/3947\tAverage_loss: 76.6622\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "BEL:\n",
      "Whe henss halle allppathe bfal ae malpresy! thathby No an. Wat orithiy ther tha thu, to aese saus,'the aifuin senith the be yorquckhar!p I'st ifs alle roun sutthatt tred inc pom jlos fa bno faar idut you? the budeat hat thelrast, Glore tows bey banen wher've bow one's\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 1700/3947\tAverage_loss: 76.2456\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "GARRAIMMKUK:\n",
      "Leet Cout.\n",
      "\n",
      "IKCEDDKGE:\n",
      "Ye. toll Ma ro nasthur ratt Sreh op?\n",
      "\n",
      "HANR:\n",
      "That thritey ou te ful thick thid gu't das?\n",
      "\n",
      "DEO OORD:\n",
      "Fusnang aprefn nof ante..\n",
      "\n",
      "ILLE:\n",
      "Dyl. Done xuk, turt I anep demeble anr.\n",
      "\n",
      "WIGMLTNHEELY:\n",
      "Se'y pas. le then's lug were corshth...\n",
      "\n",
      "ORiT\n",
      "HRAG\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 1800/3947\tAverage_loss: 75.7715\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "ERS:\n",
      "P I'tn..\n",
      "\n",
      "EATCAUMACK:\n",
      "Drouk.\n",
      "\n",
      "DEDY:\n",
      "Mhaan he Bappwy thiteste gere yous bevend aes me in, ffwas hon're've aln te bean tol fa dare heing're.\n",
      "\n",
      "KAN:\n",
      "Dgoul cpisk hotweme fod reed abi goud, lr the myon, mived hite con't dape ril you'cnt.\n",
      "\n",
      "Yeases ther aovewate domy in tiat w\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 1900/3947\tAverage_loss: 75.3140\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "DESCHETETASRENIGI Thet con'th wase?\n",
      "\n",
      "IGAD:\n",
      "Tih,  axs ang fing avelrmael?\n",
      "\n",
      "SHA\n",
      "CDLEB:\n",
      "DomeX' net an you olt, de Pl ho regart unt, domncimp at on. Nou Sht he.\n",
      "\n",
      "ULGU:\n",
      "Whe I'm ankthese nopmingan me's?\n",
      "\n",
      "TELH:\n",
      "Bon'ring ghe you nell gon tot.\n",
      "\n",
      "DESh M Hcot Feld doas hotucatRy whang\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 2000/3947\tAverage_loss: 74.8106\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "HAN:\n",
      "Shionghe shabnn sruoker it mapaisas?\n",
      "\n",
      "CO. SKI CKTHO:\n",
      "Bol,.. lomsamea How thie you has ber tooeitke con llo that thoo weed yout hius hase canching. De ned.  I top metes ait?\n",
      "\n",
      "EENKS:\n",
      "T IVpight sit backy.\n",
      "\n",
      "DENKT:\n",
      "Th, ayo riscaoaverr?\n",
      "\n",
      "W5AS:\n",
      "Thlat ous is tory tal or chro \n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 2100/3947\tAverage_loss: 74.3912\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "USANA:\n",
      "Dof I le.\n",
      "\n",
      "CBDZBE:\n",
      "Nn east. . .\n",
      "\n",
      "BAR:\n",
      "Nof hralld the mo ne las. Dick be orte at wo  arleze anche domy what stoon?\n",
      "\n",
      "Lkju dite marme. s rorm.\n",
      " hun've deret pe hibe toel. te nourt.\n",
      "\n",
      "LU:\n",
      "Lee,?\n",
      "\n",
      "B..\n",
      " MUKAROMOT:\n",
      "Thard mhe re to aik? \n",
      "I't mel co meas tomin'r.\n",
      "\n",
      "RAMACHAMOT:\n",
      "\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 2200/3947\tAverage_loss: 74.0128\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "HAP:\n",
      "Yonad.\n",
      "\n",
      "MRAN:\n",
      "A lely Moul at? Thus net.\n",
      "\n",
      "ALSOI AN:\n",
      "Unou't mamte cofus my, Sfun bowablak tharte teve? Doo ceicwe mnour...\n",
      "\n",
      "DUCHLR:\n",
      "She gought noiny.\n",
      "\n",
      "DLAPARO:\n",
      "Wheg oplon.\n",
      "\n",
      "ROS:\n",
      "I outwu chimpiy.\n",
      "\n",
      "TTEDD:\n",
      "Che litin anty fangerathay ofen we ched bean ing fome arl oplro the\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 2300/3947\tAverage_loss: 73.7192\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "TAR:\n",
      "No'm ongoestt bead suxlug..\n",
      "\n",
      "RANNA:\n",
      "I'l may ducktiveres..\n",
      "\n",
      "\n",
      "T2R:\n",
      "Seas iu Clis to nou you ot htaw? Ig an ame To ten' not ti k o the goikp is ton.\n",
      "\n",
      "TLEEYIRAO1:\n",
      "Wiad tere I moy but grert remind tan.\n",
      "\n",
      "PRECIRY:\n",
      "eit 1n sins'tle.\n",
      "\n",
      "BSASEN:\n",
      "Yontur lowhedy toord..'twe So to you\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 2400/3947\tAverage_loss: 73.3505\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "SARIP:\n",
      "Your ockt' pofy the ide...\n",
      "\n",
      "WTENRENN:\n",
      "Im you gilly at labmtis meat mu1l yourleabeolle,  ear thine..... Aep gaan cion so doumy uiigh then.\n",
      "\n",
      "RAERUMATAY:\n",
      "Pel..... I moon's us not roulls ot thid fos sut are'thorn thy taryt, zids comat sip obnn, you line naming hut. doo \n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 2500/3947\tAverage_loss: 73.0935\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "HOAN:\n",
      "Wareaor......... I'me s in'trret T Ltois you that, nou ahe or thiterbuta ton tond toont tor you  Pdat it on yout to welre me covaanke lledwist I lignowe to you Oica whtery vima romo Labithr dimdaelinw' nes yuu hit. the pedes whimeseanye adys the werry houn acous are \n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 2600/3947\tAverage_loss: 72.8301\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "YE MESML:\n",
      "Wafnning tho at you beret you wore?\n",
      "\n",
      "SRIIf:\n",
      "Dow ay hus ond howhiimeint't nceit 'nen.\n",
      "\n",
      "TOUMA:\n",
      "You my.\n",
      "\n",
      "BEURA:\n",
      "Gick cat ney?\n",
      "\n",
      "NDOH:\n",
      "Thamey. HA guanelly buon. sibshy. you I bee snangh a don'l tink.. Intragen'tme in hat.iges.. AH I't miod.\n",
      "\n",
      "IUSTORS:\n",
      "I Sigh? \n",
      "FRAM:\n",
      "Ao\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 2700/3947\tAverage_loss: 72.5927\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "JOREAM:\n",
      "Don'r do the in the youce.\n",
      "\n",
      "MSITTERL:\n",
      "No tole anote.\n",
      "\n",
      "MGAVISO:\n",
      "I've c aonqultts ove digtin gren how abeafpmowibies ckere ang! yiu thor?\n",
      "\n",
      "BORISTIBUND:\n",
      "Thlbay, dhee gors t ave hoo das sbakniy!\n",
      "\n",
      "BELLSRTELAESRT Ohe tere,.. ryo la kow int avec wore anaa sto ver net, Mle\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 2800/3947\tAverage_loss: 72.3952\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "ILAN:\n",
      "Yto fow'y ul stest,bun rut thelk that You\n",
      "\n",
      "LAIVXER:\n",
      "fod, does medime the fems, cand cank, payze to nethin uoreateay.  Oethtoat  heall... Divet therert.\n",
      "\n",
      "LOR:\n",
      "Ta tho k I acJoukat.\n",
      "\n",
      "BURAN:\n",
      "Le't  ET\n",
      "TREIyZE:\n",
      "No hoardias?\n",
      "\n",
      "FRAFR:\n",
      "Rou merin't to yofrit. gout and mean of t\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 2900/3947\tAverage_loss: 72.1356\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "LONVHERO:\n",
      "You sthes?\n",
      "\n",
      "RARAI:\n",
      "I duns. Alere, if dios doy juth ong?\n",
      "\n",
      "TER:\n",
      "Irblabe wo palls nn teranat tow the shicarioche artollveol as stulfoy Fist?\n",
      "\n",
      "GEERTE:\n",
      "Wes got hefiss on tse It rertoutbanisf muan tout thet ocou ice ing the thy\n",
      "\n",
      "II WHrive fure Thorighy,.  I leed arend \n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 3000/3947\tAverage_loss: 71.9560\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "ERBY:\n",
      "\n",
      "Gut't alil netit. Thet.\n",
      "\n",
      "SRPDE. IN:\n",
      "Thab to tire arate Is tors we get mabtete?  if... mese selk.\n",
      "\n",
      "KELBED:\n",
      "Thine dockerte eeday baik.\n",
      "\n",
      "IRAG:\n",
      "Ro. But arpeod,!\n",
      "\n",
      "KLEDAN:\n",
      "Iil, ome I mo horksed?\n",
      "\n",
      "SERLIS:\n",
      "Lit mites the fut at wit, LOke cat thust'baingon ine pelers mantt hi\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 3100/3947\tAverage_loss: 71.7711\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "PRLLSARAH:\n",
      "Whe obly. \n",
      "HUARE:\n",
      "Hpyo noe muing th.\n",
      "\n",
      "FRNEH:\n",
      "Welanl?\n",
      "\n",
      "IEBWN:\n",
      "Oat mo dodoono domytiy, Dled thay talruytimensh,ingeroul youst. Gout wnas if bonigist the on skimcorlask It't id, doujy youm sutaun now ge hiur bge's the ad wall  fo and is in..\n",
      "\n",
      "LAVW9MAN:\n",
      "I'l a burghe\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 3200/3947\tAverage_loss: 71.5584\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "SABUGA:\n",
      "A'g fos gru dorw't keorndingalt?  I SORSARLE:\n",
      "I'd ther you!\n",
      "\n",
      "THUPOE:\n",
      "What, to\n",
      "\n",
      "LOVER:\n",
      "Lo annt ih shes geikint hetad thar aatet, tand sumede sal bury thoca kmuthe pItre our jun dro cof mating ge'r sthipa keed?\n",
      "\n",
      "BAN:\n",
      "Wele opetisod, you't ende's wostcere wor it's row'\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 3300/3947\tAverage_loss: 71.3986\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "WAANBM:\n",
      "No ton't homer momank thyow.\n",
      "\n",
      "DUG:\n",
      "Wreril for nachinl, co yhe gay, suse wond you fow are gustel ume aveallr be gurtime.\n",
      "\n",
      "HAMA:\n",
      "Hut'sseis jpifs gat ik beroonpap iW.\n",
      "\n",
      "DUPERER:\n",
      "Ye,t ine diy wor hanno\n",
      "\n",
      "DOO ARP:\n",
      "It's isttellinn rown case he noels bat tom ucisns indowrin\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 3400/3947\tAverage_loss: 71.2244\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "TREFROMCH:\n",
      "I th the I ho ferend. \n",
      "HA6Ther uu Mertrer yhe wapupapike to hittandbik ah te the?\n",
      "\n",
      "DETBENERY:\n",
      "What semind be? I fopisar't igtinthy muras of mat Jind in icfoto tmee tot hereniegotrot tey Cishithe hat tou me ove ?ne Sherg?\n",
      "\n",
      "LALTOERSH:\n",
      "Than are ongt hank tit. .\n",
      "NrE\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 3500/3947\tAverage_loss: 71.0523\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "GUBADD:\n",
      "Kidigh not?\n",
      "\n",
      "HONBE:\n",
      "Whithing utling it eboulles ur mo hout're?\n",
      "\n",
      "MRAA:\n",
      "I fod tha me at yed. Sidcichinges haen corgo'm aco ther? tider hith hert he?\n",
      "\n",
      "LARGON:\n",
      "C mr timkerai hure tel toik acl hore me on.\n",
      "\n",
      "CHA:\n",
      "Yourewbing frony?\n",
      "\n",
      "PREL:\n",
      "I'd is Fand, That arery, Min ic?\n",
      " \n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 3600/3947\tAverage_loss: 70.8547\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "PIUNTHE:\n",
      "Yourit feell camw's ot by then whysertamey?\n",
      "\n",
      "TH:\n",
      "Yotases a dont ane't mickhithes Lomeo,.. I ynot pcon.\n",
      "\n",
      "WTIURY:\n",
      "Whe lyound carelpuan, laor ore sor fiy.\n",
      "\n",
      "VACKE:\n",
      "Ny.  I mur till thel loll there Mupnapcou taclo  the waver. I with now Irabveat! ga dor knon't Tfre stol\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 3700/3947\tAverage_loss: 70.6770\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "FERMER:\n",
      "Yof fo ulasawrit.  Yeky'f bure keo and ot sanng ondroulllg?\n",
      "\n",
      "VEY. IU:\n",
      "Me's mo bathase. On'g, now snoo word, Logre wrere.\n",
      "\n",
      "YWEVCEENHE:\n",
      "I lents Is gan faw are Wed wowhgry toon's arkare wout be fow ankie awath on'm ik wet im the haar you bu gos are, meld muske mteld t\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 3800/3947\tAverage_loss: 70.5191\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "PESSD:\n",
      "Nod yout maclode wo mat Mreigus\n",
      "\n",
      "MEGO:\n",
      "Hu mark me and dnist sack. Blug in you I'v the gon'th to whe, tint nouss sartinm? I lanke gowy.\n",
      "\n",
      "DANTEE:\n",
      "Blel douf have gas junt foming. Peet I go hitnly foll bion mut an wid I'N't. Aring pkauther  hes ma gect gape hiw's ape Po\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000000:\tbatch: 3900/3947\tAverage_loss: 70.3524\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "VER`\n",
      "\n",
      "SOzknorind.\n",
      "\n",
      "Dkongt!\n",
      "\n",
      "SVuwleginver?\n",
      "\n",
      "MWh?\n",
      "\n",
      "WWequp4d'tsxh!\n",
      "\n",
      "\n",
      "G74 darngguengd!\n",
      "\n",
      "Juldern'dry,\n",
      "\n",
      "Jfuct\n",
      "\n",
      "\n",
      "WRBt'lliong!\n",
      "\n",
      "Ru7Che, \n",
      "99gos,!\n",
      "\n",
      "\n",
      "CHwaverss nxs, hext llisitnJund\n",
      "\n",
      "Vxke,!\n",
      "\n",
      "G0y't?\n",
      "\n",
      "PPchit ghtst?\n",
      "\n",
      "SZU\n",
      "\n",
      "BW8\n",
      "Pxevth!\n",
      "\n",
      "LOX\n",
      "\n",
      "VXKungizt?\n",
      "\n",
      "INVquznnk,, vid.\n",
      "\n",
      "SOV\n",
      "HARzikXywh yn\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch:   53/3947\tAverage_loss: 70.2035\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "DWh, sefikng,, jog, nofrongxng\n",
      "\n",
      "Jqutong sn's ligh, napkd,!\n",
      "\n",
      "\n",
      "GE6kQfughttrongnght'ldod!\n",
      "\n",
      "VA`knoZk, hvenghat nthrknd?\n",
      "\n",
      "PVDoknok.\n",
      "\n",
      "Rit'ld, 9lik?\n",
      "\n",
      "CDxkthest?\n",
      "\n",
      "VRed'r.\n",
      "\n",
      "M9\n",
      "\n",
      "\n",
      "FI'Vwish, kngongenngongnk Wachs!\n",
      "\n",
      "GWik?\n",
      "\n",
      "MKXR6remk.\n",
      "\n",
      "`5.\n",
      "\n",
      "LOZk..\n",
      "\n",
      "JUind!\n",
      "\n",
      "\n",
      "PWhe brethy?\n",
      "\n",
      "ROJE:\n",
      "Dremve!\n",
      "\n",
      "\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch:  153/3947\tAverage_loss: 70.0313\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "CK:\n",
      "\n",
      "6Qksond?\n",
      "\n",
      "\n",
      "VOikgnit jlatt?\n",
      "\n",
      "Vf7mbbegrist ganldstreddfrmenngh,rsst\n",
      "\n",
      "SJungitrll, knathengn?\n",
      "\n",
      "Whikngrng,, ot's'd bxwavevmedcyken'rngrg'mnk?\n",
      "\n",
      "\n",
      "WM3X.\n",
      "\n",
      "Dlghe!\n",
      "\n",
      "WQThoun'lllg.\n",
      "\n",
      "PWnournon'th.\n",
      "\n",
      "4xmings kneggo1rng, bvesterkngxyngsngits ketten, Dldsthd!\n",
      "\n",
      "COV9jut rid, hopacknitn, \n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch:  253/3947\tAverage_loss: 69.8696\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "X9IVknoxt\n",
      "\n",
      "TJ0ongwn chok, lurd Bgown't Whizmedd,, negrn'l?\n",
      "\n",
      "MYK19GB`Yicdongzm5 yhttt logithtgnghed gstelchingcnggt'n'verdont know'tht nop Bevine.. Whand clave fure ol go deth k.\n",
      "\n",
      "SoARIT:\n",
      "I dow ankinte in, theithot me elistap. But an's  I fuckee we4 knout naydy than't of Aa\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch:  353/3947\tAverage_loss: 69.6813\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "INIA:\n",
      "Fxat as.\n",
      "\n",
      "DR.'Go The womind, loter. theos. It emuge met the dess tcat some's been Capgfane Butontat that pary. to dreatinger couck. Threl. Sate. .DEY:\n",
      "ofs ge stotken. I thore. Wever her. Axy herga, wen, wes and nover.\n",
      "\n",
      "LUKE:\n",
      "Ace deike yur.\n",
      "\n",
      "CTE:\n",
      "You bigs eo. ICKpethe\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch:  453/3947\tAverage_loss: 69.5297\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "MARK:\n",
      "Lom dald peam..\n",
      "BENI Y:\n",
      "Thaw, your.\n",
      "\n",
      "JACSEIMINKHE:\n",
      "Whaw. I'le you miow an, wann't go? Id me.. Bik, fe sathy. this is?\n",
      "RAFDDY:\n",
      "Lall 2acquy, soon the yours in Ka heeve hin's and terportect thome.\n",
      "\n",
      "DANZH:\n",
      "Me?\n",
      "\n",
      "SACKR:\n",
      "Hime herly qurt, Wand to Non... I'gr?\n",
      "\n",
      "MREKS:\n",
      "MML. I \n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch:  553/3947\tAverage_loss: 69.3285\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "FFRATE:\n",
      "You, I Dreel por.\n",
      "\n",
      "DON3E:\n",
      "Mlged you'ss you ruyd.\n",
      "\n",
      "HY:\n",
      "Ms rebon ofen fug? Whet union's yoys futhiny jacte'm corouns yom comive titerly hasy wak up?\n",
      "\n",
      "LUMED:\n",
      "\n",
      "Qk.\n",
      "\n",
      "\n",
      "GANSA.. ve? fowall withand.c..\n",
      "\n",
      "CALOCE:\n",
      "ROVE:\n",
      "Ygeoon'g tat thect it sive wing iortond.\n",
      "\n",
      "COVE:\n",
      "Att cat s\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch:  653/3947\tAverage_loss: 69.2886\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "DORO MR. THICK:\n",
      "So lidedsthin' tha wollin't lickouetin.\n",
      "\n",
      "GOMONK:\n",
      "I cay nomep and sfild Bekyne socky't more ger.\n",
      "\n",
      "KOFREY:\n",
      "Andeat a proe Thesd hat gen, go. WHI wwod utalln tak I plene roy? Be me the the sol goe go edind here ave youd toO cearshonme thave. goure, thaipy ifret\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch:  753/3947\tAverage_loss: 69.1791\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "PANWER:\n",
      "AR in bas?\n",
      "\n",
      "DUKon\n",
      "\n",
      "HAUAN:\n",
      "Tikn.\n",
      "\n",
      "RWE:\n",
      "I jus aloult I'rigw fepe the ke utnes, a sigh, sod ot hameligr wit'lle herke up. I Jupuitt yungw!. wod to ktore? Me'f me, meres that stell way sho le, tersere's pily you got in'g.\n",
      "\n",
      "DEVERAAR.... I've you chimer mone.\n",
      "\n",
      "DORES:\n",
      "Ael\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch:  853/3947\tAverage_loss: 69.0407\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "NI Cuss kees. Your Gusan you you liantce a speck I wonthalins you TDamk ankimge you wit' reaur dot. Bowmur get yon. .\n",
      "\n",
      "PIECK:\n",
      "Bidc. go beny igghe a abloper to Wweldn. Thar Yathis by mee pee you, thith, a kyoure't pichas mised it bure don't ghe nof way to tipdit whichn'm ba\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch:  953/3947\tAverage_loss: 68.8835\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "VOOVIN:\n",
      "Yeare think or oy. Heone?\n",
      "\n",
      "JOR:\n",
      "I beal that abot, sank, wave, I a pakit. Ithocnghelr to wald un fin's tey sin't...\n",
      "\n",
      "CKUNMY:\n",
      "I'mrettere aver wellys hes ow ofsabkcoun ut a Do kanyen dourd ot.\n",
      "\n",
      "NINOMR:\n",
      "on wisteer.\n",
      "\n",
      "JEUFREE:\n",
      "No you' revibk, bigh dutry.  DWherd go nets'\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 1053/3947\tAverage_loss: 68.7398\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "K:\n",
      "LuWk of herp filpebay.\n",
      "\n",
      "MORLTOR. AVIANEY:\n",
      "EU. SHAN:\n",
      "Ect you  puke. Che herdooce tod?\n",
      "\n",
      "JEFFREY:\n",
      "What you Penne net eroug?\n",
      "\n",
      "ELUK:\n",
      "I'd ure  femame ut rey ay's of gethe cor'r?\n",
      "\n",
      "OTPAYNK:\n",
      "Yot's res, there. doud eend the the you I bor wabigh?  medtir stann wackea in.\n",
      "\n",
      "GORARENI\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 1153/3947\tAverage_loss: 68.6187\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "HUNTUN:\n",
      "Wel on ha ! and's dise thit it upoug Horer wbeeer you whats juld hald thid bon youen nitro. Pule Vo sow and yout yow? Lit, di? jup herhe. Ancay.\n",
      "\n",
      "DEFFRR:\n",
      "Ohs not, the's.\n",
      "\n",
      "MR DUTERPENDW: gitay Shat tin, tod i in.\n",
      "\n",
      "JEROY:\n",
      "Sowe san you litutt the womy thistind wite li\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 1253/3947\tAverage_loss: 68.5167\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "JERI BI Toverld.\n",
      "\n",
      "DENDY:\n",
      "I the ritte beey. Ang fido a Lis, whe to walkhe foctar, I knonoing, high.\n",
      "\n",
      "ERIE:\n",
      "Mboed you got ayun on's itene. I'x eate amy herolens the. I abig.. Civ.\n",
      "\n",
      "FRIEl:\n",
      "Fover waby! Poo'.\n",
      "\n",
      "INEY:\n",
      "THLo Digh. Whon wand jam. I Refel me.. I'trikiik ive shapcnemu\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 1353/3947\tAverage_loss: 68.3912\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "GONT:\n",
      "You.\n",
      "\n",
      "EDDY:\n",
      "It? Good ceas fleald worl I nigtaall in bemeodsfir don't mat coly hore. jude do pork over bey tad gales. I cays? Luaral 'f go sthopling you here you tat of, thes arreddet? We. tom!\n",
      "\n",
      "FCHATH:\n",
      "No. YoE juct. The's do dinged, way Ir fuoongi lend sarin sererkar\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 1453/3947\tAverage_loss: 68.2329\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "EDDY:\n",
      "I's a migu see syod 'ur wile coud beag Fo wacs.\n",
      "\n",
      "LAPDY:\n",
      "I nod nayns topit nads the.... I men town.\n",
      "\n",
      "BARPED:\n",
      "By't gorn been neb on it I mache. I'mo onw ond.\n",
      "\n",
      "HGRPEN:\n",
      "Yer. Then inade tere I Gudt recte's Zewisar she in hat yousamatel, I rlourt.\n",
      "\n",
      "STE:\n",
      "He weilg. rat.... I\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 1553/3947\tAverage_loss: 68.0921\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "DY:\n",
      "BOG's thanita feme ccor, to wamlat mills micke dunt.\n",
      "\n",
      "FANDY:\n",
      "Hightere bery he. I fchowa ne fans to Sioo onm anl thaw?\n",
      "\n",
      "YLEDZITE:\n",
      "I dimaing it segemt you shiss.  WOS ME IONEAN:\n",
      "Okat flomen wing. Shes nat's id iveor noun, Hel to.\n",
      "\n",
      "EDDY:\n",
      "ow?\n",
      "\n",
      "FRARTHINrY:\n",
      "Whatmred we sneat\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 1653/3947\tAverage_loss: 68.0142\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "MRNBEY:\n",
      "Fow, JQiandolging got sou racnem me ow it on thimer hore foler Hee?\n",
      "\n",
      "FILARDDY:\n",
      "I an you knet regn ap. Itpout be fure Row toy's and mat, leding haut ink thith bunky.\n",
      "\n",
      "SA NESICD. Shtel a to juth heaving wanlet mhoustar.  Ore ou this has in nonvid I illik tos.\n",
      "\n",
      "FRED:\n",
      "\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 1753/3947\tAverage_loss: 67.9048\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "FREVCHEX:\n",
      "Hikey thar ge cut cerhfall, ceehise that and the mullst id.\n",
      "\n",
      "DO SANDIN:\n",
      "No kne's ploona keoinge?\n",
      "\n",
      "DESTOLL:\n",
      "Af I po kens ofering akry.\n",
      "\n",
      "FENN:\n",
      "Angimenen thor on waf meapes comebe tonound?\n",
      "\n",
      "LANHY:\n",
      "So ceat! Dondy.\n",
      "\n",
      "IG:\n",
      "No? AC she she deing a gight wo nof fullind Fora\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 1853/3947\tAverage_loss: 67.7879\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "GAN:\n",
      "Yeupere?\n",
      "\n",
      "LI bu'm 'lroongin't te.\n",
      "\n",
      "KOR:\n",
      "IN?\n",
      "\n",
      "HONDEY:\n",
      "lecteyto anby an tavlond!\n",
      "\n",
      "WABESMAD:\n",
      "Sousayh. Car yet preisusls.\n",
      "\n",
      "WAFFRDY:\n",
      "Tham, mtay, to abe pighe fumhind. INfiuan youxad bu's out' lied oze fig of tor nes ank stoss panew obsothing aojof andege plored aiss Whenke\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 1953/3947\tAverage_loss: 67.6781\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "OANK! G? I kyor thitsand.\n",
      "\n",
      "BEN:\n",
      "Theet, That iontte what methis, is?\n",
      "\n",
      "LICHIP:\n",
      "I Plon.. I''ve the jut Vupf.\n",
      "\n",
      "TALD:\n",
      "Thipr, ase Ghat be't king to fosbod. Ti'm Cinatt in as gy fing sort!\n",
      "\n",
      "DOMLUK WHUKT nveelvew tom a prom, the oun sood he, Reeve.\n",
      "\n",
      "BEN:\n",
      "I tebe ksure mo nochered B\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 2053/3947\tAverage_loss: 67.5629\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "JEFLY:\n",
      "Thengo, doul.\n",
      "\n",
      "SABEk jy's dad't\n",
      "\n",
      "JUThorfnlgvas gonk! Tor, bryor in fika ther sokeef. Cous os tokend's bint that so ips bockur?\n",
      "\n",
      "ICKA:\n",
      "Oweanel the and haml hard thirk eokire's the doin?\n",
      "\n",
      "RAPIG COA:\n",
      "Nor.....\n",
      "\n",
      "JANUL:\n",
      "Dime geant arsh to meve to andet?\n",
      "\n",
      "RHEL:\n",
      "I Se is mem\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 2153/3947\tAverage_loss: 67.4657\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "CHE8KXI'll!\n",
      "\n",
      "WRUSCK:\n",
      "Shendk.\n",
      "\n",
      "\n",
      "JE9\n",
      "\n",
      "EYKRZSZOR:\n",
      "Oke car, jall it'm I bentustts oustfing and allet it ell my here.  I' to Meth the thy.\n",
      "\n",
      "FRED:\n",
      "I'm ule , ger but eve. I're.  than' mt I mack stoy!\n",
      "\n",
      "BAM:\n",
      "I'  Mangme mer it'l foroe.\n",
      "\n",
      "TERLD:\n",
      "Hemge.\n",
      "\n",
      "LAVYOLRY:\n",
      "Alu the wonsemn solly\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 2253/3947\tAverage_loss: 67.3595\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "DURA\n",
      "\n",
      "JEF\n",
      "BOVE5G6A\n",
      "\n",
      "VONI\n",
      "\n",
      "BERX\n",
      "\n",
      "KTROT:\n",
      "CAgd, thand\n",
      "\n",
      "RERUZOS You'ld?\n",
      "\n",
      "DABWh?\n",
      "\n",
      "DD3ANSTOL:\n",
      "\n",
      "Konw youss llith?\n",
      "\n",
      "Cowennk lightthk Zo you.\n",
      "\n",
      "LELIN:\n",
      "Mt appinetry if ite whoural touy fods.\n",
      "\n",
      "\n",
      "LUONG:\n",
      "Do your simhe.  nowh?\n",
      "\n",
      "LELALE:\n",
      "Dnthe mese the tojing gocngalen mey.  om ok yinthint?\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 2353/3947\tAverage_loss: 67.2590\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "RAMI:\n",
      "We avent.\n",
      "\n",
      "CORSSTR:\n",
      "Cuckis... furespeed ik.\n",
      "\n",
      "ERATHAR:\n",
      "Ht? Nreybing thitexe reay frened tal lay?\n",
      "\n",
      "LANRITY:\n",
      "I'm ony.\n",
      "\n",
      "BEN:\n",
      "Theytery netthe arot go.  Wterew.  fuar tor gise the.\n",
      "\n",
      "MRSELEHN:\n",
      "No It's doming a not.\n",
      "\n",
      "JAUL:\n",
      "Let sak.... goig do ovley, the hour hate qut yottrin\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 2453/3947\tAverage_loss: 67.1583\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "PRHINAAD:\n",
      "Mn.\n",
      "\n",
      "IAN:\n",
      "Yet I'f bur ken alle.  at it dich gord. I's mioo, wom is wightt ceming awl do.\n",
      "\n",
      "DONNA:\n",
      "Nid?\n",
      "\n",
      "LUMARDE: at anlede is bedbe pimebe fpee to knew telly.\n",
      "\n",
      "SARD:\n",
      "Enthore neth, wonding tould, not oud I'lid about chell.\n",
      "\n",
      "MRET\n",
      "LAUPATAR:\n",
      "You.\n",
      "\n",
      "TTE:\n",
      "They gotedtort?\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 2553/3947\tAverage_loss: 67.0936\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "ALBORa dotter ow anG in. They inm done thhtelulen broghapwhe femtqujun't goring buck to netere.  I thy thas me. wofe....\n",
      "\n",
      "YONZA:\n",
      "Je harcill ceme?\n",
      "\n",
      "BYMThA:LOh.\n",
      "\n",
      "JELN:\n",
      "Ths hered you thay0 of thy kestind diseing Shaake. Cel hi.. I grrot itees.\n",
      "\n",
      "JEFR:\n",
      "Mense, wave., ar? Onvis s\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 2653/3947\tAverage_loss: 67.0032\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "DETNITPALIN:\n",
      "A?\n",
      "\n",
      "CORP:\n",
      "Thanl.  he you here bealyedras and wore th?  thad.\n",
      "\n",
      "SROTHAREL:\n",
      "I ofptherall is it dock lad.\n",
      "\n",
      "TORUTBETR:\n",
      "Afullacts sit go thu geclest's cer thirr tavedase. wo that.\n",
      "\n",
      "DEIS YlME NI Ax. A's onm.\n",
      "\n",
      "MRIGA:\n",
      "The what the dey ane homy\n",
      "\n",
      "SARON:\n",
      "Shely find ay hur\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 2753/3947\tAverage_loss: 66.9543\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "MUVERM:\n",
      "Ont'll donally. Wime ongeme..  ks ad sooing will de he that yoe Shesshonttio that thel an. tizew hang, Thaken thet of just yoith helll fhathe on ofering qures th there. You cor Jung you Theny bo to chanseflinee. Anve thot so o  Thanon?\n",
      "\n",
      "JANR:\n",
      "Whe d case.\n",
      "\n",
      "HRATH:\n",
      "I \n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 2853/3947\tAverage_loss: 66.8724\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "BOHNEN:\n",
      "Aen! ..... I the to sfor.\n",
      "\n",
      "TELWIETELSATH:\n",
      "Nohs ot he shavent bec a re't tes it quind I's the?\n",
      "\n",
      "RANATY:\n",
      "I onllimpberestid in at naugeous int the becorestaan thy duploed, you aad he.  I back the.  So a me thibkeren I you...\n",
      "\n",
      "HERGO fanace sis wavt?\n",
      "\n",
      "PROAD:\n",
      "Nok that to\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 2953/3947\tAverage_loss: 66.7998\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "JONN:\n",
      "I hod merert\n",
      "\n",
      "MLBESMOX:\n",
      "What of to lig Id tal, inn.\n",
      "\n",
      "KERBEITH:\n",
      "Thercer... shey have astel conth?\n",
      "\n",
      "AORBEA:\n",
      "Buckponast of out whe lid.. That supse, Doulr is im an hack rit...\n",
      "\n",
      "TRALIE:\n",
      "The t0 bedy ov bak at to Das fnow to That ey humlay.\n",
      "\n",
      "LECKO:\n",
      "Epaid lin't gould to I'N\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 3053/3947\tAverage_loss: 66.7339\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "P9Quvknire, dy sumeve.!\n",
      "\n",
      "DDENLENK:\n",
      "What yit, Do. UrE that atter sro ant Peror brebe cof that wave the at be the is., fat you gurdeleld?\n",
      "\n",
      "HED:\n",
      "We bucked. but'l.  It moGetes?\n",
      "\n",
      "JOR:\n",
      "I sen here thas ise doy!\n",
      "\n",
      "ROMIENE:\n",
      "BOYes istheid, doung he, wave sanbone wof spoing, whirbys t\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 3153/3947\tAverage_loss: 66.6531\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "REI THNo knomymedqay.  I'valg ryouneve atrind.  It'm you?\n",
      "\n",
      "DRWLEY:\n",
      "I got eake to this too the oudm.\n",
      "\n",
      "RAHTAN:\n",
      "You we sthempeis o gart.. Bont getid doud.\n",
      "\n",
      "LESShr.\n",
      "\n",
      "REETO INMD:\n",
      "I seeburedut seeprarly.\n",
      "\n",
      "KORDESH:\n",
      "Lea. ., Yhewe?\n",
      "\n",
      "FARIUS ER'S nem Fxat abling it you denknoct abruy\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 3253/3947\tAverage_loss: 66.5987\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "DDET TBI Trah.. SA dithee woud ctemeg to the the be cand pny for rirre.\n",
      "\n",
      "EEMAE:\n",
      "Whe crore in, yar warthe. What the are?\n",
      "\n",
      "DETER:\n",
      "Yow sareeld thing.\n",
      "\n",
      "CANNTO:\n",
      "canilm it oxn wa berm, noy tollll  pol hat at dor't gegor bO te frare the leemthat in dined I Arusare. I a Weseld the\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 3353/3947\tAverage_loss: 66.5390\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "DUNBEN:\n",
      "Thercink stach.\n",
      "\n",
      "PERET WOEFR:\n",
      "Wha how somangid'll sorser af, of abit, tore's poras me.\n",
      "\n",
      "DALDY:\n",
      "You weokere fulls meels com, stind you're an Fuver hall ond your berlist h. de ast I'd beaccioned thy esndion!\n",
      "\n",
      "DENBEST:\n",
      "ow we anc... movemle if the pim?\n",
      "\n",
      "DR.  Bpbe, \n",
      "JA'\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 3453/3947\tAverage_loss: 66.4552\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "JOHN:\n",
      "Puned?\n",
      "\n",
      "DU:\n",
      "Gupnmn thedenckell you ig, win thit that I and homced peres offry assep Cind ibrill ghen we gheghe?\n",
      "\n",
      "ELKAPA:\n",
      "I'm do, Mallys, Cick to is expraymsering pvece liking.... beffy.\n",
      "\n",
      "LEPRORECCINDDEN:\n",
      "Luthe. I ghe allist in huy you da all.  I OLACKRIINDY:\n",
      "Thavamum\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 3553/3947\tAverage_loss: 66.4013\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "MANPENDY:\n",
      "Dilr wigracp Beeighs mulest!  Yey I men you't demoo. KO tpaseny losiled wow.\n",
      "\n",
      "YISE:\n",
      "I storl tomwry? There wnoedo, now yould, filllo.\n",
      "\n",
      "LIA:\n",
      "I fuptemy not thile and wover parchiy. 'wvanex a mer.\n",
      "\n",
      "CINTY:\n",
      "Do!\n",
      "\n",
      "EDBON:\n",
      "I herl lighing. You dile wime a knou, I'lu andid t\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 3653/3947\tAverage_loss: 66.3190\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "PRON:\n",
      "Tha the crameise.\n",
      "\n",
      "LONAAD:\n",
      "I 's I sacut you dere yours. FI's sherturouvs. The Th. Thed pleyuged sild in thit cowd to Ameld bell ucfort,  fat?\n",
      "\n",
      "LOKA:\n",
      "Youstey, beffotind that is prorle.. bigo It. Poll howe wet the onis nbace veam.\n",
      "\n",
      "TROFNY:\n",
      "Her biel bifr be suld's bas w\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 3753/3947\tAverage_loss: 66.2493\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "JETOR..\n",
      "\n",
      "GET:\n",
      "Whaceed sus wo athiz. Uhim of thent?\n",
      "\n",
      "WERLLOGE:\n",
      "I wod Lots in't a knoo's Ray tueld is, fink.\n",
      "\n",
      "llppike.  St it noudet ro thibit, Humis.. justiply. purdreF wain lome bownderte mat!\n",
      "\n",
      "MEFRIE:\n",
      "AIGlavad. in of ainds I the fo breat. I fih woach of ane juckack thelr \n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000001:\tbatch: 3853/3947\tAverage_loss: 66.1855\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "ESAROME:\n",
      "ROF INKOR:\n",
      "Whe pome.  oppomy Dle's healds I kedlers tod'm. Andich, tasd he, Tigaite ferestat ove Ficliny minm.! I xodrin'vnen ig?.\n",
      "\n",
      "LyKE:\n",
      "Weizend rostrevir wowh no Bill ton't\n",
      "\n",
      "EL TERQIt:\n",
      "Th, te to prost, thymermuem that'ld hey whated to me wo jus os ig's epen tith\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000002:\tbatch:    6/3947\tAverage_loss: 66.1201\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "MANDA:\n",
      "You seam, wham. The you the in's it cill fionmyen depend a Gey'rrye tron, Bege, sa fon buck.\n",
      "\n",
      "GOTO:\n",
      "Yer jucteming that not.\n",
      "\n",
      "REUNDOF:\n",
      "You're was, eilly int's amell taghcnee, in.\n",
      "\n",
      "LANN:\n",
      "Me hane wink.  What in. I wit's mion be is. Bis lied womlyng ee wit's. I't I'm ne\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000002:\tbatch:  106/3947\tAverage_loss: 66.0497\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "MONZE:\n",
      "Whas? gorteon go at goy't're cat the do bon's hive is bow, thip of hicht Bake you lece mys, Jid? I've you the ponat ey.... shiy an't heachit I's hisen whemsidinn. then's breysy you rot sume gy't, they cond \n",
      "SORMOME TCHANIEST:\n",
      "You Mames you msweat you dousn Bat she q\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000002:\tbatch:  206/3947\tAverage_loss: 65.9756\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "DUK:\n",
      "I Jips Pead?\n",
      "\n",
      "HAA:\n",
      "I's think . On's amn rit to Ses that it tein tull af dound musesswe. yeadd. Pald mur he ckel dourainf on teve sind stillnt. I caly wer.\n",
      "\n",
      "Dus undy have amed ?.. sa lard Walker.\n",
      "\n",
      "YMRAT:\n",
      "What bu rik?\n",
      "\n",
      "DR INKO:\n",
      "Yowe wave.\n",
      "\n",
      "TTRWHRE:\n",
      "Heo'll daknous.\n",
      "\n",
      "DONN\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000002:\tbatch:  306/3947\tAverage_loss: 65.8870\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "MUVERBEI KI's dan's your?\n",
      "\n",
      "DAMTR:\n",
      "Trey.\n",
      "\n",
      "JEEMR. BY:\n",
      "Thathind hessaoce, mit. Gusy disial.!, bekend onn't hels to eved sad.. I knouzing ofle. I, I 've natozed that? I can thyser a wors bire?..\n",
      "\n",
      "COESH:\n",
      "Whiscigh. Tw ou, we's sald Gurciling will a sure nover fone a me it cow bu\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000002:\tbatch:  406/3947\tAverage_loss: 65.8150\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "MRDIE:\n",
      "Me metibk I't Ekn goly that onsbouth dooun, to gut wert, she cere's in.\n",
      "\n",
      "PUDEY:\n",
      "That're doon't  Dr T RI'm lithat ave on you, nike.\n",
      "\n",
      "LUKAR:\n",
      "AN, makn for 'ved.\n",
      "\n",
      "CHORTY:\n",
      "Yim of you whouke theel on so to be ging?. I thit if that Ig over. Whitharn't plour be....\n",
      "\n",
      "GUKE:\n",
      "W\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000002:\tbatch:  506/3947\tAverage_loss: 65.7293\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "8ARLAY:\n",
      "Se sordor.\n",
      "\n",
      "MR., Whirks..\n",
      "\n",
      "JEFFRET:\n",
      "Yet it him. Dorllsed do poot Reeroon't mehs sur?\n",
      "\n",
      "SONFE:\n",
      "I'm fono you ecoune.\n",
      "\n",
      "HNDY:\n",
      "Hemsfen dice an me, a mepe rupp. Whay are.. I gond be?\n",
      "\n",
      "MUKERPICSE:\n",
      "What's doint that you't That tow be's hewrintte, Jish hame. And rear thing n\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000002:\tbatch:  606/3947\tAverage_loss: 65.6464\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "JEFFRUK:\n",
      "Yhe knowtatay wuad nan't mor. That your hase ale saasew on a whack han tied beeve whot radbealait beartsrithing on's lock us like bace toin your it?\n",
      "\n",
      "MARDY:\n",
      "I?. Whit have you gowerse madter of migh.\n",
      "\n",
      "AWHIHE:\n",
      "Haopes.\n",
      "\n",
      "DUKER:\n",
      "Newr.\n",
      "\n",
      "IR. PFRLEINK:\n",
      "You kight. Ittat? I\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000002:\tbatch:  706/3947\tAverage_loss: 65.5753\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "MRESKE:\n",
      "Freop! you do there.\n",
      "\n",
      "CANDUROND:\n",
      "Beoll car, care.. Weday. Bug anly. s sowht?\n",
      "\n",
      "JCICTE:\n",
      "EUf KEFFREGORN WHFRI\n",
      "ELAIVE1LUHPY:\n",
      "Ye! I they bes I'd supper pely.  Anding ciax aplea the look hell, kney, thes benaled afly ifs like hir shit falled your a rasay. SYa deene. Your\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000002:\tbatch:  806/3947\tAverage_loss: 65.5129\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "IL:\n",
      "Sfoan's they what anid he'r all che'rybe hharet my justle ansy?\n",
      "\n",
      "MCIN:\n",
      "Youring on of theve the  tole watangistay.\n",
      "\n",
      "MR. JOFFREY:\n",
      "Nwily C2meatry Coad. I kfichen ast to ale wof?\n",
      "\n",
      "THIALD:\n",
      "Do.\n",
      "\n",
      "CHARYE:\n",
      "Yo tow in I Elaren. It's of mloon't cofss.\n",
      "\n",
      "DUK:\n",
      "Ga dit.\n",
      "\n",
      "DIET:\n",
      "Whas im \n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000002:\tbatch:  906/3947\tAverage_loss: 65.4248\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "JBEYO:\n",
      "What prere chell a lack habete Ithing net it reat's to I lo, Ifardy i herchard selinmen't beel has we come thy bean't.  a kuthe.\n",
      "\n",
      "DUKE:\n",
      "Dight wan to forde wet have theane thanaing. I'vem arse? Wawtser wheren'temyoler.\n",
      "HONKE:\n",
      "What weak shont hinh Heant. Noven cowa li\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000002:\tbatch: 1006/3947\tAverage_loss: 65.3446\n",
      "HAN:\n",
      "Is that good or bad?\n",
      "\n",
      "EEN:\n",
      "Heil thas itt. A llin, mustsmldione. I'm Gurfe you ueld ware.\n",
      "\n",
      "OVERFFRIITEROSY:\n",
      "\n",
      "KEY:\n",
      "GOCTERICTR:CHe Ramnide beffe thint. At buckink of lit.\n",
      "\n",
      "MUVERIWPRY:\n",
      "Whe'flity?\n",
      "\n",
      "SANDY:\n",
      "Nowid Ormeno I'lred store prow plof net fee it it!\n",
      "\n",
      "JOFFRA:\n",
      "Caboe iver stobinttiing hoadces sel\n",
      "\n",
      "> Dumped to: ./model\n",
      "epoch: 000002:\tbatch: 1106/3947\tAverage_loss: 65.2716\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(batch_size=5, sequence_length=30)\n",
    "dataset.preprocess(\"dataset/selected_conversations.txt\")\n",
    "dataset.create_minibatches()\n",
    "rnn = run_language_model(dataset, 100000, sequence_length=dataset.sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded...\n",
      "HAN:\n",
      "Nemos\n",
      "\n",
      "\n",
      "ANZY:\n",
      "I pilp, Beve K stele yeut wa te ave tos aor, fit withe theent Gos not thick bitheney, you hite mad wicx you oy simo and you ar for wtoml. YoI a the guve tu bimeto teat t ace anct allay urd at at owe tatoorint, MaR bit thiin than.\n",
      "\n",
      " WAIVE:\n",
      "You miths that!\n",
      "\n",
      "SREDY:\n",
      "Thit nory uvienco \n"
     ]
    }
   ],
   "source": [
    "path = './model'\n",
    "with open(path, 'rb') as f:\n",
    "    rnn = pickle.load(f)\n",
    "print(\"Loaded...\")\n",
    "\n",
    "\n",
    "seed = \"HAN:\\nNemos\\n\\n\"\n",
    "n_sample = 300\n",
    "sampled = sample(rnn, seed, n_sample, dataset)\n",
    "print(''.join(sampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
