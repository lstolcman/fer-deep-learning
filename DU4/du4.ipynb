{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys_version: 3.5.2 (default, Nov 17 2016, 17:05:23) [GCC 5.4.0 20160609]\n",
      "virtual_env None\n",
      "pwd /home/marko/Projects/faks/DU/DU4\n",
      "np  1.11.1\n",
      "tf  0.10.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pdb\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('sys_version:', sys.version.replace('\\n', ''))\n",
    "print('virtual_env', os.environ.get('VIRTUAL_ENV', 'None'))\n",
    "print('pwd', os.getcwd())\n",
    "print('np ', np.__version__)\n",
    "print('tf ', tf.__version__)\n",
    "\n",
    "\n",
    "from IPython.core.debugger import Tracer\n",
    "BREAK_POINT = lambda: Tracer()()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_prob(probs):\n",
    "    \"\"\"Uzorkovanje vektora x prema vektoru vjerojatnosti p(x=1) = probs\"\"\"\n",
    "    return tf.nn.relu(tf.sign(probs - tf.random_uniform(tf.shape(probs))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utils.py\n",
    "\n",
    "\"\"\" This file contains different utility functions that are not connected\n",
    "in anyway to the networks presented in the tutorials, but rather help in\n",
    "processing the outputs into a more understandable way.\n",
    "\n",
    "For example ``tile_raster_images`` helps in generating a easy to grasp\n",
    "image from a set of samples or weights.\n",
    "\"\"\"\n",
    "\n",
    "import numpy\n",
    "\n",
    "\n",
    "def scale_to_unit_interval(ndar, eps=1e-8):\n",
    "    \"\"\" Scales all values in the ndarray ndar to be between 0 and 1 \"\"\"\n",
    "    ndar = ndar.copy()\n",
    "    ndar -= ndar.min()\n",
    "    ndar *= 1.0 / (ndar.max() + eps)\n",
    "    return ndar\n",
    "\n",
    "\n",
    "def tile_raster_images(X, img_shape, tile_shape, tile_spacing=(0, 0),\n",
    "                       scale_rows_to_unit_interval=True,\n",
    "                       output_pixel_vals=True):\n",
    "    \"\"\"\n",
    "    Transform an array with one flattened image per row, into an array in\n",
    "    which images are reshaped and layed out like tiles on a floor.\n",
    "\n",
    "    This function is useful for visualizing datasets whose rows are images,\n",
    "    and also columns of matrices for transforming those rows\n",
    "    (such as the first layer of a neural net).\n",
    "\n",
    "    :type X: a 2-D ndarray or a tuple of 4 channels, elements of which can\n",
    "    be 2-D ndarrays or None;\n",
    "    :param X: a 2-D array in which every row is a flattened image.\n",
    "\n",
    "    :type img_shape: tuple; (height, width)\n",
    "    :param img_shape: the original shape of each image\n",
    "\n",
    "    :type tile_shape: tuple; (rows, cols)\n",
    "    :param tile_shape: the number of images to tile (rows, cols)\n",
    "\n",
    "    :param output_pixel_vals: if output should be pixel values (i.e. int8\n",
    "    values) or floats\n",
    "\n",
    "    :param scale_rows_to_unit_interval: if the values need to be scaled before\n",
    "    being plotted to [0,1] or not\n",
    "\n",
    "\n",
    "    :returns: array suitable for viewing as an image.\n",
    "    (See:`Image.fromarray`.)\n",
    "    :rtype: a 2-d array with same dtype as X.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(img_shape) == 2\n",
    "    assert len(tile_shape) == 2\n",
    "    assert len(tile_spacing) == 2\n",
    "\n",
    "    # The expression below can be re-written in a more C style as\n",
    "    # follows :\n",
    "    #\n",
    "    # out_shape    = [0,0]\n",
    "    # out_shape[0] = (img_shape[0]+tile_spacing[0])*tile_shape[0] -\n",
    "    #                tile_spacing[0]\n",
    "    # out_shape[1] = (img_shape[1]+tile_spacing[1])*tile_shape[1] -\n",
    "    #                tile_spacing[1]\n",
    "    out_shape = [\n",
    "        (ishp + tsp) * tshp - tsp\n",
    "        for ishp, tshp, tsp in zip(img_shape, tile_shape, tile_spacing)\n",
    "    ]\n",
    "\n",
    "    if isinstance(X, tuple):\n",
    "        assert len(X) == 4\n",
    "        # Create an output numpy ndarray to store the image\n",
    "        if output_pixel_vals:\n",
    "            out_array = numpy.zeros((out_shape[0], out_shape[1], 4),\n",
    "                                    dtype='uint8')\n",
    "        else:\n",
    "            out_array = numpy.zeros((out_shape[0], out_shape[1], 4),\n",
    "                                    dtype=X.dtype)\n",
    "\n",
    "        #colors default to 0, alpha defaults to 1 (opaque)\n",
    "        if output_pixel_vals:\n",
    "            channel_defaults = [0, 0, 0, 255]\n",
    "        else:\n",
    "            channel_defaults = [0., 0., 0., 1.]\n",
    "\n",
    "        for i in range(4):\n",
    "            if X[i] is None:\n",
    "                # if channel is None, fill it with zeros of the correct\n",
    "                # dtype\n",
    "                dt = out_array.dtype\n",
    "                if output_pixel_vals:\n",
    "                    dt = 'uint8'\n",
    "                out_array[:, :, i] = numpy.zeros(\n",
    "                    out_shape,\n",
    "                    dtype=dt\n",
    "                ) + channel_defaults[i]\n",
    "            else:\n",
    "                # use a recurrent call to compute the channel and store it\n",
    "                # in the output\n",
    "                out_array[:, :, i] = tile_raster_images(\n",
    "                    X[i], img_shape, tile_shape, tile_spacing,\n",
    "                    scale_rows_to_unit_interval, output_pixel_vals)\n",
    "        return out_array\n",
    "\n",
    "    else:\n",
    "        # if we are dealing with only one channel\n",
    "        H, W = img_shape\n",
    "        Hs, Ws = tile_spacing\n",
    "\n",
    "        # generate a matrix to store the output\n",
    "        dt = X.dtype\n",
    "        if output_pixel_vals:\n",
    "            dt = 'uint8'\n",
    "        out_array = numpy.zeros(out_shape, dtype=dt)\n",
    "\n",
    "        for tile_row in range(tile_shape[0]):\n",
    "            for tile_col in range(tile_shape[1]):\n",
    "                if tile_row * tile_shape[1] + tile_col < X.shape[0]:\n",
    "                    this_x = X[tile_row * tile_shape[1] + tile_col]\n",
    "                    if scale_rows_to_unit_interval:\n",
    "                        # if we should scale values to be between 0 and 1\n",
    "                        # do this by calling the `scale_to_unit_interval`\n",
    "                        # function\n",
    "                        this_img = scale_to_unit_interval(\n",
    "                            this_x.reshape(img_shape))\n",
    "                    else:\n",
    "                        this_img = this_x.reshape(img_shape)\n",
    "                    # add the slice to the corresponding position in the\n",
    "                    # output array\n",
    "                    c = 1\n",
    "                    if output_pixel_vals:\n",
    "                        c = 255\n",
    "                    out_array[\n",
    "                        tile_row * (H + Hs): tile_row * (H + Hs) + H,\n",
    "                        tile_col * (W + Ws): tile_col * (W + Ws) + W\n",
    "                    ] = this_img * c\n",
    "        return out_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Zadatak 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "#from utils import tile_raster_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias(shape):\n",
    "    initial = tf.zeros(shape, dtype=tf.float32)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def sample_prob(probs):\n",
    "    \"\"\"Uzorkovanje vektora x prema vektoru vjerojatnosti p(x=1) = probs\"\"\"\n",
    "    return tf.nn.relu(\n",
    "        tf.sign(probs - tf.random_uniform(tf.shape(probs))))\n",
    "\n",
    "\n",
    "def draw_weights(W, shape, N, interpolation=\"bilinear\"):\n",
    "    \"\"\"Vizualizacija težina\n",
    "    \n",
    "    W -- vektori težina\n",
    "    shape -- tuple dimenzije za 2D prikaz težina - obično dimenzije ulazne slike, npr. (28,28)\n",
    "    N -- broj vektora težina\n",
    "    \"\"\"\n",
    "    image = Image.fromarray( tile_raster_images(\n",
    "        X=W.T,\n",
    "        img_shape=shape,\n",
    "        tile_shape=(int(math.ceil(N/20)), 20),\n",
    "        tile_spacing=(1, 1)))\n",
    "    plt.figure(figsize=(10, 14))\n",
    "    plt.imshow(image, interpolation=interpolation)\n",
    "    \n",
    "def draw_reconstructions(ins, outs, states, shape_in, shape_state):\n",
    "    \"\"\"Vizualizacija ulaza i pripadajućih rekonstrkcija i stanja skrivenog sloja\n",
    "    ins -- ualzni vektori\n",
    "    outs -- rekonstruirani vektori\n",
    "    states -- vektori stanja skrivenog sloja\n",
    "    shape_in -- dimezije ulaznih slika npr. (28,28)\n",
    "    shape_state -- dimezije za 2D prikaz stanja (npr. za 100 stanja (10,10)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 12*4))\n",
    "    for i in range(20):\n",
    "\n",
    "        plt.subplot(20, 4, 4*i + 1)\n",
    "        plt.imshow(ins[i].reshape(shape_in), vmin=0, vmax=1, interpolation=\"nearest\")\n",
    "        plt.title(\"Test input\")\n",
    "        plt.subplot(20, 4, 4*i + 2)\n",
    "        plt.imshow(outs[i][0:784].reshape(shape_in), vmin=0, vmax=1, interpolation=\"nearest\")\n",
    "        plt.title(\"Reconstruction\")\n",
    "        plt.subplot(20, 4, 4*i + 3)\n",
    "        plt.imshow(states[i][0:(shape_state[0] * shape_state[1])].reshape(shape_state), vmin=0, vmax=1, interpolation=\"nearest\")\n",
    "        plt.title(\"States\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# my utils\n",
    "\n",
    "def h_prob(v_prob, w, v_b):\n",
    "    return tf.nn.sigmoid(tf.matmul(v_prob, w) + tf.transpose(v_b))\n",
    "\n",
    "\n",
    "def v_prob(h_prob, w, h_b):\n",
    "    return tf.nn.sigmoid(tf.matmul(h_prob, tf.transpose(w)) + tf.transpose(h_b))\n",
    "\n",
    "def get_w1_grad(v, h):    \n",
    "    v = tf.reshape(v, [-1, int(v.get_shape()[1]), 1])\n",
    "    h = tf.reshape(h, [-1, 1, int(h.get_shape()[1])])\n",
    "    # batch i vanjski produkt\n",
    "    product = tf.reduce_sum(tf.batch_matmul(v, h), reduction_indices=0) \n",
    "    return product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images,mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# net\n",
    "Nv = 784\n",
    "v_shape = (28,28)\n",
    "Nh = 100\n",
    "h1_shape = (10,10)\n",
    "\n",
    "gibbs_sampling_steps = 1\n",
    "alpha = 0.1 # koeficijent učenja \n",
    "\n",
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    X1 = tf.placeholder(\"float\", [None, 784])\n",
    "    w1 = weights([Nv, Nh])\n",
    "    vb1 = bias([Nv])\n",
    "    hb1 = bias([Nh])\n",
    "    \n",
    "    v0_prob = sample_prob(X1)  \n",
    "    h0_prob = h_prob(v0_prob, w1, hb1)\n",
    "    h0 = sample_prob(h0_prob)\n",
    "    h1 = h0\n",
    "\n",
    "    for step in range(gibbs_sampling_steps):\n",
    "        v1_prob = v_prob(h1, w1, vb1) \n",
    "        v1 = sample_prob(v1_prob)\n",
    "        h1_prob = h_prob(v1, w1, hb1)\n",
    "        h1 = sample_prob(h1_prob)\n",
    "    \n",
    "    # pozitivna faza\n",
    "    w1_positive_grad = get_w1_grad(X1, h0_prob)\n",
    "    \n",
    "    # negativna faza\n",
    "    w1_negative_grad = get_w1_grad(v1_prob, h1_prob)    \n",
    "\n",
    "    dw1 = (w1_positive_grad - w1_negative_grad) / tf.to_float(tf.shape(X1)[0])\n",
    "\n",
    "    # operacije za osvježavanje parametara mreže - one pokreću učenje RBM-a\n",
    "    update_w1 = tf.assign_add(w1, alpha * dw1)\n",
    "    update_vb1 = tf.assign_add(vb1, alpha * tf.reduce_mean(X1 - v1_prob, 0))\n",
    "    update_hb1 = tf.assign_add(hb1, alpha * tf.reduce_mean(h0 - h1, 0)) \n",
    "\n",
    "    out1 = (update_w1, update_vb1, update_hb1)\n",
    "    \n",
    "    # rekonstrukcija ualznog vektora - koristimo vjerojatnost p(v=1)\n",
    "    v1_prob =  v_prob(h1_prob, w1, vb1)\n",
    "    \n",
    "    err1 = X1 - v1_prob\n",
    "    err_sum1 = tf.reduce_mean(err1 * err1)\n",
    "    \n",
    "    initialize1 = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch count:  0   Avg. reconstruction error:  0.244637\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3739765aed7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0merr_sum1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 710\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    711\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 908\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 958\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    959\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    945\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    946\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 100\n",
    "n_samples = mnist.train.num_examples\n",
    "\n",
    "total_batch = int(n_samples / batch_size) * epochs\n",
    "\n",
    "with tf.Session(graph=g1) as sess:\n",
    "    sess.run(initialize1)\n",
    "    for i in range(total_batch):\n",
    "        batch, label = mnist.train.next_batch(batch_size)\n",
    "        err, _ = sess.run([err_sum1, out1], feed_dict={X1: batch})\n",
    "        \n",
    "        if i%(int(total_batch/10)) == 0:\n",
    "            print(\"Batch count: \", i, \"  Avg. reconstruction error: \", err)\n",
    "    \n",
    "    w1s = w1.eval()\n",
    "    vb1s = vb1.eval()\n",
    "    hb1s = hb1.eval()\n",
    "    vr, h1_probs, h1s = sess.run([v1_prob, h1_prob, h1], feed_dict={X1: teX[0:2,:]})\n",
    "\n",
    "# vizualizacija težina\n",
    "draw_weights(w1s, v_shape, Nh) \n",
    "\n",
    "# vizualizacija rekonstrukcije i stanja\n",
    "draw_reconstructions(teX, vr, h1s, v_shape, h1_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zadatak 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
